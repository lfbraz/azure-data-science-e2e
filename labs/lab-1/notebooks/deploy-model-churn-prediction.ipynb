{"cells":[{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"c1e4e7e2-6a63-493b-9b27-bc3afe8ff405","showTitle":false,"title":""}},"source":["## Deploy churn prediction model\n","In this notebook we will demonstrate how to get the model generated [here]() to deploy it. We need to follow these steps:\n","\n","- Get an already trained model\n","- Instantiate an Azure ML Workspace\n","- Build an image with the best model packaged\n","- Deploy the model to ACI (Azure Container Instance)\n","- Deploy the model to AKS (Azure Kubernetes Services)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"3006dd14-9eaf-4eab-9a80-95b3c27179e5","showTitle":false,"title":""}},"source":["## First lets get the model\n","Return the best model from `churn-prediction` experiment. We will use the same notebook **model-churn-prediction** and return the `model_uri`."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"fdf14873-f10f-47c1-aa42-6a15970d3f12","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>"]},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"","metadata":{},"type":"ipynbError"}},"output_type":"display_data"}],"source":["%run ./model-churn-prediction"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"f67b27e6-0a59-40da-bca8-3e63b5ff9e4b","showTitle":false,"title":""}},"source":["And load the `xgboost` using the `model_uri` returned from MLFlow tracking."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"a00fd3a4-aecd-4142-8c9c-11361bebaa65","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>"]},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"","metadata":{},"type":"ipynbError"}},"output_type":"display_data"}],"source":["import mlflow\n","\n","model = mlflow.xgboost.load_model(model_uri)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"139ad7c6-8c59-4508-9094-490c791fa81d","showTitle":false,"title":""}},"source":["## Get Azure Machine Learning Workspace\n","We will use Azure Machine Learning to deliver the API `endpoints` that will consume the Machine Learning models. To be able to interact with Azure ML we will use [Azure Machine Learning Python SDK](https://docs.microsoft.com/en-us/python/api/overview/azure/ml/?view=azure-ml-py), with it its possible to create new workspaces (or use existing ones) to facilitate the deployment process.\n","\n","Its required to fill the variables `WORKSPACE_NAME`, `WORKSPACE_LOCATION`, `RESOURCE_GROUP` and `SUBSCRIPTION_ID` with your subscription data.\n","\n","As default will be required the `Interactive Login` auth. For production scenarios an app registration with `Service Principal` is required. In the [documentation] (https://docs.microsoft.com/en-us/azure/machine-learning/how-to-setup-authentication#set-up-service-principal-authentication) we have more details about the different kind of authentications."]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"954fcb98-c523-4af4-8186-c2864807a83e","showTitle":false,"title":""}},"source":["First install the [`azureml-sdk`](https://pypi.org/project/azureml-sdk/)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"349fe25a-2c4f-45b5-85c8-7c7892bc3d21","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>"]},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"","metadata":{},"type":"ipynbError"}},"output_type":"display_data"}],"source":["!pip install azureml-sdk"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"2f35bd39-459c-46f8-a28d-c4b0e820a80a","showTitle":false,"title":""}},"source":["And now we can use it to instantiate the Azure ML Workspace"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"89c676d1-307f-459c-b28a-59021c99e8aa","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>"]},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"","metadata":{},"type":"ipynbError"}},"output_type":"display_data"}],"source":["import azureml\n","from azureml.core import Workspace\n","import mlflow.azureml\n","\n","workspace_name = '<YOUR-WORKSPACE-NAME>'\n","resource_group = '<YOUR-RESOURCE-GROUP>'\n","subscription_id = '<YOUR-SUBSCRIPTION-ID>'\n","\n","workspace = Workspace.get(name = workspace_name,\n","                          resource_group = resource_group,\n","                          subscription_id = subscription_id)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"b2e08801-c5b9-462d-a5eb-dfd90cbabee7","showTitle":false,"title":""}},"source":["## Register the model\n","Now we instantiate the Azure ML Workspace we can register the model. First we will persist it to the dbfs (to be able to pass the path as a parameters to Azure ML Register)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"463aedfa-3b5f-4f33-ac01-6366840c4128","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>"]},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"","metadata":{},"type":"ipynbError"}},"output_type":"display_data"}],"source":["import shutil\n","model_path = '/dbfs/models/churn-prediction'\n","\n","# Delete old files if necessary\n","try:\n","  shutil.rmtree(model_path)\n","except FileNotFoundError:\n","  print (\"Cleanig model directory: {} \\nThis directory hasn't been created yet.\".format(model_path))\n","else:\n","    print (\"Cleanig model directory: {} \\nDirectory successfully cleaned.\".format(model_path))\n","  \n","# Persist the XGBoost model\n","mlflow.xgboost.save_model(model, model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"7ee90d72-4395-4f59-9758-6ba8045b5d1e","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>"]},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"","metadata":{},"type":"ipynbError"}},"output_type":"display_data"}],"source":["from azureml.core.model import Model\n","\n","model_name = 'churn-model'\n","model_description = 'Modelo de predição de churn utilizando XGBoost'\n","\n","model_azure = Model.register(model_path = model_path,\n","                             model_name = model_name,\n","                             description = model_description,\n","                             workspace = workspace,\n","                             tags={'Framework': \"XGBoost\", 'Tipo': \"Classificação\"}\n","                             )"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"36f69111-a164-4060-9738-fd8dffa55d9a","showTitle":false,"title":""}},"source":["A new model version was generated in the Azure ML Workspace. We can use it to deploy an API with ACI or AKS."]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"2f8c5f20-3a7d-4d48-93ac-0394d5dfd7d1","showTitle":false,"title":""}},"source":["# Deploy\n","Now with the registered model we can choose between two deployment types: `ACI` (Azure Container Instance) or `AKS` (Azure Kubernetes Service).\n","\n","For development scenarios it is better to use `ACI` and for production `AKS` will have more options related to scalability and security. Please see more details in this [page](https://docs.microsoft.com/en-us/azure/architecture/reference-architectures/ai/mlops-python)."]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"cfd1d4c0-ceb1-4737-87e3-37c961762a21","showTitle":false,"title":""}},"source":["### Entry script\n","But before deploy the model, it is important to define an **`entry script`** named score.py. It will be responsible to load the model when the deployed service starts and for receiving data, passing it to the model, and then returning a response as well (see this [link](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-existing-model#define-inference-configuration)).\n","\n","The package [`inference-schema`](https://github.com/Azure/InferenceSchema) will be used to help to set some schema decorators. It is very useful specially to automatically generated a [**swagger ready**](https://en.wikipedia.org/wiki/Swagger_(software) documentation."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"7b359424-a23d-4aa7-957c-f79ec0e6ee0e","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>"]},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"","metadata":{},"type":"ipynbError"}},"output_type":"display_data"}],"source":["!pip install inference-schema"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"1be49f3c-b93f-4d4d-998b-d97b3f12db51","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>"]},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"","metadata":{},"type":"ipynbError"}},"output_type":"display_data"}],"source":["%%writefile /dbfs/models/churn-prediction/score.py\n","\n","import mlflow\n","import json\n","import pandas as pd\n","import os\n","import xgboost as xgb\n","import time\n","import numpy as np\n","\n","from inference_schema.schema_decorators import input_schema, output_schema\n","from inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\n","from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n","\n","# Called when the deployed service starts\n","def init():\n","    global model\n","    global train_stats\n","    \n","    # Get the path where the deployed model can be found.\n","    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), './churn-prediction')\n","    \n","    # Load model\n","    model = mlflow.xgboost.load_model(model_path)\n","\n","# Our sample payload (to be able to automatically generate swagger file)\n","input_sample = pd.DataFrame(data=[{\"Idade\": 21,\n","                                   \"RendaMensal\": 9703, \n","                                   \"PercentualUtilizacaoLimite\": 1.0, \n","                                   \"QtdTransacoesNegadas\": 5.0, \n","                                   \"AnosDeRelacionamentoBanco\": 12.0, \n","                                   \"JaUsouChequeEspecial\": 0.0, \n","                                   \"QtdEmprestimos\": 1.0, \n","                                   \"NumeroAtendimentos\": 100, \n","                                   \"TMA\": 300, \n","                                   \"IndiceSatisfacao\": 2, \n","                                   \"Saldo\": 6438, \n","                                   \"CLTV\": 71}])\n","\n","# This is an integer type sample. Use the data type that reflects the expected result.\n","output_sample = np.array([0])\n","\n","@input_schema('data', PandasParameterType(input_sample))\n","@output_schema(NumpyParameterType(output_sample))\n","def run(data):\n","    try:\n","        print(\"receiving input_data....\")\n","        print(data.columns)\n","\n","        data_xgb = xgb.DMatrix(data)\n","        \n","        print(\"predicting....\")\n","        result = model.predict(data_xgb)\n","\n","        print(\"result.....\")\n","        print(result)\n","    # You can return any data type, as long as it can be serialized by JSON.\n","        return result.tolist()\n","    except Exception as e:\n","        error = str(e)\n","        return error"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"1693c3c5-3de3-4b12-9f58-956ac65032d2","showTitle":false,"title":""}},"source":["### Inference config\n","We must now add some inference configs to be used in the endpoint. We can add required packages and an environment that can be registered in the Azure ML Workspace.\n","\n","Here we will use the same `conda.yaml` file that is already registered from MLFlow process. We will add the `azureml-defaults` package that can be used in the inference process."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"d148093a-0fb4-4273-9a10-e72906b5b3a1","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>"]},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"","metadata":{},"type":"ipynbError"}},"output_type":"display_data"}],"source":["from azureml.core.model import InferenceConfig\n","from azureml.core.environment import Environment\n","from azureml.core.conda_dependencies import CondaDependencies\n","\n","# Create the environment\n","env = Environment(name='xgboost_env')\n","\n","conda_dep = CondaDependencies('/dbfs/models/churn-prediction/conda.yaml')\n","\n","# Define the packages needed by the model and scripts\n","conda_dep.add_pip_package(\"azureml-defaults\")\n","conda_dep.add_pip_package(\"inference-schema\")\n","\n","# Adds dependencies to PythonSection of myenv\n","env.python.conda_dependencies=conda_dep\n","\n","inference_config = InferenceConfig(entry_script=\"/dbfs/models/churn-prediction/score.py\",\n","                                   environment=env)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"3e92f716-8a7c-4b2e-a47c-545e423b2f97","showTitle":false,"title":""}},"source":["Now with the inference config we can proceed with the deployment"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"8fb6f71f-21f6-44a8-8054-b4d52a969a48","showTitle":false,"title":""}},"source":["###ACI - Azure Container Instance\n","Follow we will demonstrate how to create an `endpoint` using the image created before and delivering with `ACI`."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"f6b153c0-c545-4733-80aa-7c572b89b897","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>"]},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"","metadata":{},"type":"ipynbError"}},"output_type":"display_data"}],"source":["from azureml.core.webservice import AciWebservice, Webservice\n","from azureml.exceptions import WebserviceException\n","from azureml.core.model import Model\n","\n","endpoint_name = 'api-churn-dev'\n","\n","deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1, auth_enabled=True)\n","service = Model.deploy(workspace, endpoint_name, [model_azure], inference_config, deployment_config, overwrite=True)\n","service.wait_for_deployment(show_output = True)\n","\n","print('A API {} foi gerada no estado {}'.format(service.scoring_uri, service.state))"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"c58d0ebd-ece4-4782-9a97-41dde98c1ff1","showTitle":false,"title":""}},"source":["## Load some data to test the endpoint\n","We will use the same dataset used to train the model only for testing purposes."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"ee20fc20-51de-4b39-a9f9-acd5e2c69127","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>"]},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"","metadata":{},"type":"ipynbError"}},"output_type":"display_data"}],"source":["import requests\n","import json\n","\n","# A churn payload\n","payload1 = {\n","    \"data\":\n","    [\n","        {\n","            'Idade': \"21\",\n","            'RendaMensal': \"9703\",\n","            'PercentualUtilizacaoLimite': \"1\",\n","            'QtdTransacoesNegadas': \"5\",\n","            'AnosDeRelacionamentoBanco': \"12\",\n","            'JaUsouChequeEspecial': \"0\",\n","            'QtdEmprestimos': \"1\",\n","            'NumeroAtendimentos': \"100\",\n","            'TMA': \"300\",\n","            'IndiceSatisfacao': \"2\",\n","            'Saldo': \"6438\",\n","            'CLTV': \"71\",\n","        },\n","    ],\n","}\n","\n","payload1 = str.encode(json.dumps(payload1))\n","\n","# A non-churn payload\n","payload2 = {\n","    \"data\":\n","    [\n","        {\n","            'Idade': \"48\",\n","            'RendaMensal': \"9703\",\n","            'PercentualUtilizacaoLimite': \"1\",\n","            'QtdTransacoesNegadas': \"5\",\n","            'AnosDeRelacionamentoBanco': \"12\",\n","            'JaUsouChequeEspecial': \"0\",\n","            'QtdEmprestimos': \"1\",\n","            'NumeroAtendimentos': \"1\",\n","            'TMA': \"300\",\n","            'IndiceSatisfacao': \"5\",\n","            'Saldo': \"6438\",\n","            'CLTV': \"71\",\n","        },\n","    ],\n","}\n","\n","payload2 = str.encode(json.dumps(payload2))"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"78c4a40e-4b97-489b-b007-ad5acad7febc","showTitle":false,"title":""}},"source":["## Call the API\n","Make two requests to the API using `payload1` and `payload2`. The API url can be obtained throught `service.scoring_uri` generated from deployment process."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"171c117a-52a7-4249-907c-0d9a60cf1352","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>"]},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"","metadata":{},"type":"ipynbError"}},"output_type":"display_data"}],"source":["dev_service_key = service.get_keys()[0] if len(service.get_keys()) > 0 else None\n","\n","headers = {'Content-Type': 'application/json'}\n","headers[\"Authorization\"] = \"Bearer {service_key}\".format(service_key=dev_service_key)\n","\n","response1 = requests.request(\"POST\", service.scoring_uri, headers=headers, data=payload1)\n","response2 = requests.request(\"POST\", service.scoring_uri, headers=headers, data=payload2)\n","\n","print(response1.text)\n","print(response2.text)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"5c42236b-7301-4dc1-b891-6424f5fc8f57","showTitle":false,"title":""}},"source":["It is also possible to use API using any client to make HTTP requests (curl, postman, etc.)."]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"4f475584-4235-4678-b82c-8a11e8e9219d","showTitle":false,"title":""}},"source":["## Azure Kubernetes Services (AKS)\n","For production scenarios it is better to deploy using AKS because we have more benefits about security and scalability.\n","\n","In this scenario is possible to follow two ways: Creating a new AKS cluster or targeting to an existing one. In this tutorial we will create a new cluster."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"b9ce189f-7dfe-4a3f-be77-f138b4de8d62","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>"]},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"","metadata":{},"type":"ipynbError"}},"output_type":"display_data"}],"source":["from azureml.core.webservice import AksWebservice\n","from azureml.core.compute import AksCompute, ComputeTarget\n","\n","aks_name = 'aks-e2e-ds'\n","\n","prov_config = AksCompute.provisioning_configuration()\n","\n","aks_target = ComputeTarget.create(workspace = workspace, name = aks_name, provisioning_configuration = prov_config)\n","\n","#If you want to use an existing AKS cluster, comment the previous command line e un-comment the next one:\n","#aks_target = AksCompute(workspace, aks_name)\n","\n","aks_target.wait_for_completion(show_output = True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"9bc9a94d-c4b3-49fc-8785-1f7493eec72c","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>"]},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"","metadata":{},"type":"ipynbError"}},"output_type":"display_data"}],"source":["from azureml.core.compute import AksCompute, ComputeTarget\n","\n","aks_name = 'aks-e2e-ds'\n","aks_target = ComputeTarget(workspace=workspace, name=aks_name)\n","\n","# Deleting aks cluster\n","#aks_target.delete()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"fcdb58af-90b2-4403-99e8-42bfbb0567cd","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>"]},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"","metadata":{},"type":"ipynbError"}},"output_type":"display_data"}],"source":["from azureml.core.webservice import AksWebservice\n","\n","endpoint_name = 'api-churn-prod'\n","\n","aks_config = AksWebservice.deploy_configuration(compute_target_name=aks_name)\n","\n","aks_service = Model.deploy(workspace=workspace,\n","                           name=endpoint_name,\n","                           models=[model_azure],\n","                           inference_config=inference_config,\n","                           deployment_config=aks_config,\n","                           deployment_target=aks_target,\n","                           overwrite=True\n","                          )\n","\n","aks_service.wait_for_deployment(show_output = True)\n","print(aks_service.state)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"6154bf9c-f936-42bc-ad96-834333ce453b","showTitle":false,"title":""}},"source":["## Call the API (with AKS)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"9ccbf703-2272-4fbf-a1d7-8068190b05c4","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>"]},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"","metadata":{},"type":"ipynbError"}},"output_type":"display_data"}],"source":["prod_service_key = aks_service.get_keys()[0] if len(aks_service.get_keys()) > 0 else None\n","\n","headers = {'Content-Type': 'application/json'}\n","headers[\"Authorization\"] = \"Bearer {service_key}\".format(service_key=prod_service_key)\n","\n","response1 = requests.request(\"POST\", aks_service.scoring_uri, headers=headers, data=payload1)\n","response2 = requests.request(\"POST\", aks_service.scoring_uri, headers=headers, data=payload2)\n","\n","print(response1.text)\n","print(response2.text)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"experimentId":"4050486937759260","pythonIndentUnit":2},"notebookName":"deploy-model-churn-prediction","notebookOrigID":4050486937759261,"widgets":{}},"interpreter":{"hash":"d5db60dca472e4618b9afc87b9d235cf6d331e458d5e0e1f810a82c1dae15b1b"},"kernelspec":{"display_name":"Python 3.7.6 64-bit ('.venv': venv)","name":"python3"},"language_info":{"name":"python","version":""}},"nbformat":4,"nbformat_minor":0}
